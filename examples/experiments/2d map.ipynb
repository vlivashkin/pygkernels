{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygraphs.graphs.generator import StochasticBlockModel\n",
    "from pygraphs.measure import kernels\n",
    "from pygraphs.cluster import KernelKMeansSklearn, KernelWardSklearn\n",
    "from pygraphs.scenario import ParallelByGraphs, measures_right_order\n",
    "from pygraphs.scorer import copeland\n",
    "from pygraphs.util import load_or_calc_and_save, ddict2dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Calc a 2d field p_in vs p_out for several n and k (balanced classes)\n",
    "\n",
    "$$\n",
    "n = 50, 100, 150, 200 \\\\\n",
    "k = 2, 3, 4, 5, 10 \\\\\n",
    "p_{in}, p_{out} \\in (0, 1] \\text{ with step}=0.05\n",
    "$$\n",
    "\n",
    "mean (or median) by 100 graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_colors = dict([(k.name, i) for i, k in enumerate(kernels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellMeasureResults:\n",
    "    def __init__(self, name, params, ari, error):\n",
    "        self.measure_name = name\n",
    "        self.params = params\n",
    "        self.ari = ari\n",
    "        self.error = error\n",
    "    \n",
    "    def mari(self, method='max'):\n",
    "        if method == 'max':\n",
    "            return np.nanmax(self.ari)\n",
    "        elif method == 'mean':\n",
    "            return np.nanmean(self.ari)\n",
    "        elif method == 'median':\n",
    "            return np.nanmedian(self.ari)\n",
    "\n",
    "\n",
    "class PictureCellResults:\n",
    "    def __init__(self):\n",
    "        self.measure_results = {}\n",
    "    \n",
    "    def best_measure(self):\n",
    "        measure_results_list = [(measure_name, measure_result.mari(method='max')) \\\n",
    "                                for measure_name, measure_result in self.measure_results.items()]\n",
    "        measure_results_list = sorted(measure_results_list, key=lambda x: x[1], reverse=True)\n",
    "        return measure_results_list[0]  # tuple (name, ari)\n",
    "    \n",
    "\n",
    "class PictureResults:\n",
    "    def __init__(self, name, n_pin, n_pout):\n",
    "        self.name = name\n",
    "        self.results = [[PictureCellResults() for _ in range(n_pout)] for _ in range(n_pin)]\n",
    "        \n",
    "    def best_measure_map(self, kernel_colors):\n",
    "        measure_map = np.full((len(self.results), len(self.results[0])), np.nan)\n",
    "        ari_map = np.full((len(self.results), len(self.results[0])), np.nan)\n",
    "        for i in range(len(self.results)):\n",
    "            for j in range(len(self.results[0])):\n",
    "                name, ari = self.results[i][j].best_measure()\n",
    "                measure_map[i, j] = kernel_colors[name]\n",
    "                ari_map[i, j] = ari \n",
    "        return measure_map, ari_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337c7ed63e2f4e43a8ef784a3f187815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='100_2_KernelKMeansSklearn', max=441, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0, 0.0, SCCT -- error\n",
      "0.0, 0.0, PPR -- error\n",
      "0.0, 0.0, logPPR -- error\n",
      "0.0, 0.0, HeatPPR -- error\n",
      "0.0, 0.0, logHeatPPR -- error\n",
      "0.0, 0.05, SCCT -- error\n",
      "0.0, 0.05, PPR -- error\n",
      "0.0, 0.05, logPPR -- error\n",
      "0.0, 0.05, HeatPPR -- error\n",
      "0.0, 0.05, logHeatPPR -- error\n",
      "0.0, 0.1, SCCT -- error\n",
      "0.0, 0.1, PPR -- error\n",
      "0.0, 0.1, logPPR -- error\n",
      "0.0, 0.1, HeatPPR -- error\n",
      "0.0, 0.1, logHeatPPR -- error\n",
      "0.0, 0.15000000000000002, SCCT -- error\n",
      "0.0, 0.15000000000000002, PPR -- error\n",
      "0.0, 0.15000000000000002, logPPR -- error\n",
      "0.0, 0.15000000000000002, HeatPPR -- error\n",
      "0.0, 0.15000000000000002, logHeatPPR -- error\n",
      "0.05, 0.0, SCCT -- error\n",
      "0.05, 0.0, PPR -- error\n",
      "0.05, 0.0, logPPR -- error\n",
      "0.05, 0.0, HeatPPR -- error\n",
      "0.05, 0.0, logHeatPPR -- error\n",
      "0.05, 0.05, SCCT -- error\n",
      "0.05, 0.05, PPR -- error\n",
      "0.05, 0.05, logPPR -- error\n",
      "0.05, 0.05, HeatPPR -- error\n",
      "0.05, 0.05, logHeatPPR -- error\n",
      "0.05, 0.1, SCCT -- error\n",
      "0.05, 0.1, PPR -- error\n",
      "0.05, 0.1, logPPR -- error\n",
      "0.05, 0.1, HeatPPR -- error\n",
      "0.05, 0.1, logHeatPPR -- error\n",
      "0.05, 0.15000000000000002, SCCT -- error\n",
      "0.05, 0.15000000000000002, PPR -- error\n",
      "0.05, 0.15000000000000002, logPPR -- error\n",
      "0.05, 0.15000000000000002, HeatPPR -- error\n",
      "0.05, 0.15000000000000002, logHeatPPR -- error\n",
      "0.1, 0.0, SCCT -- error\n",
      "0.1, 0.0, PPR -- error\n",
      "0.1, 0.0, logPPR -- error\n",
      "0.1, 0.0, HeatPPR -- error\n",
      "0.1, 0.0, logHeatPPR -- error\n",
      "0.1, 0.05, SCCT -- error\n",
      "0.1, 0.05, PPR -- error\n",
      "0.1, 0.05, logPPR -- error\n",
      "0.1, 0.05, HeatPPR -- error\n",
      "0.1, 0.05, logHeatPPR -- error\n",
      "0.1, 0.1, SCCT -- error\n",
      "0.1, 0.1, PPR -- error\n",
      "0.1, 0.1, logPPR -- error\n",
      "0.1, 0.1, HeatPPR -- error\n",
      "0.1, 0.1, logHeatPPR -- error\n",
      "0.15000000000000002, 0.0, SCCT -- error\n",
      "0.15000000000000002, 0.0, PPR -- error\n",
      "0.15000000000000002, 0.0, logPPR -- error\n",
      "0.15000000000000002, 0.0, HeatPPR -- error\n",
      "0.15000000000000002, 0.0, logHeatPPR -- error\n",
      "0.2, 0.0, SCCT -- error\n",
      "0.2, 0.0, PPR -- error\n",
      "0.2, 0.0, logPPR -- error\n",
      "0.2, 0.0, HeatPPR -- error\n",
      "0.2, 0.0, logHeatPPR -- error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ns = [100]\n",
    "ks = [2]\n",
    "estimators = [KernelKMeansSklearn]\n",
    "step = 0.05\n",
    "p_ins = np.arange(0.0, 1.0001, step)\n",
    "p_outs = np.arange(0.0, 1.0001, step)\n",
    "\n",
    "overall_results = {}\n",
    "\n",
    "classic_plot = ParallelByGraphs(adjusted_rand_score, np.linspace(0, 1, 31), progressbar=False)\n",
    "for n, k, estimator in product(ns, ks, estimators):  # one picture\n",
    "    experiment_name = f'{n}_{k}_{estimator.name}'\n",
    "    picture_results = PictureResults(experiment_name, p_ins.shape[0], p_outs.shape[0])\n",
    "    overall_results[experiment_name] = picture_results\n",
    "    for p_in, p_out in tqdm(list(product(p_ins, p_outs)), desc=experiment_name):  # one pixel\n",
    "        p_in_idx, p_out_idx = int(p_in / step), int(p_out / step)\n",
    "        cell_results = picture_results.results[p_in_idx][p_out_idx]\n",
    "        graphs, info = StochasticBlockModel(n, k, p_in=p_in, p_out=p_out).generate_graphs(100)\n",
    "        for kernel in kernels:\n",
    "            try:\n",
    "                params, ari, error = classic_plot.perform(estimator, kernel, graphs, k, n_jobs=12)\n",
    "            except KeyboardInterrupt:\n",
    "                exit(1)\n",
    "            except:\n",
    "                print(f'{p_in}, {p_out}, {kernel.name} -- error')\n",
    "                params, ari, error = [], [], []\n",
    "            cell_results.measure_results[kernel.name] = CellMeasureResults(kernel.name, params, ari, error)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'overall_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63fdeb1a1b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mari\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'100_2_KernelKMeansSklearn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_measure_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'overall_results' is not defined"
     ]
    }
   ],
   "source": [
    "colors, ari = overall_results['100_2_KernelKMeansSklearn'].best_measure_map(kernel_colors)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(colors)\n",
    "ax[0].set_xticks(range(p_ins.shape[0]))\n",
    "ax[0].set_yticks(range(p_outs.shape[0]))\n",
    "ax[0].set_xticklabels(p_ins)\n",
    "ax[0].set_yticklabels(p_outs)\n",
    "ax[0].set_xlabel('$p_{in}$')\n",
    "ax[0].set_ylabel('$p_{out}$')\n",
    "\n",
    "ax[1].imshow(ari, vmin=0, vmax=1)\n",
    "ax[1].set_xticks(range(p_ins.shape[0]))\n",
    "ax[1].set_yticks(range(p_outs.shape[0]))\n",
    "ax[1].set_xticklabels(p_ins)\n",
    "ax[1].set_yticklabels(p_outs)\n",
    "ax[1].set_xlabel('$p_{in}$')\n",
    "ax[1].set_ylabel('$p_{out}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9c29405bfd42e0a52abd28d33827a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='100_2_KernelKMeansSklearn', max=441, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "picture_results = overall_results['100_2_KernelKMeansSklearn']\n",
    "jjson = {}\n",
    "for p_in, p_out in tqdm(list(product(p_ins, p_outs)), desc=experiment_name):  # one pixel\n",
    "    p_in_idx, p_out_idx = int(p_in / step), int(p_out / step)\n",
    "    cell_results = picture_results.results[p_in_idx][p_out_idx]\n",
    "\n",
    "    jcell = {}\n",
    "    for measure_result in cell_results.measure_results.values():\n",
    "        jcell[measure_result.measure_name] = {\n",
    "            'params': [x.tolist() for x in measure_result.params],\n",
    "            'ari': [x.tolist() for x in measure_result.ari],\n",
    "            'error': [x.tolist() for x in measure_result.error]\n",
    "        }\n",
    "    jjson[f'{p_in}, {p_out}'] = jcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.json', 'w') as f:\n",
    "    json.dump(jjson, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
